{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nConnectome Predictive Modelling\n===============================\n**What you'll learn**: Build a linear model from functional\nconnectivity matrices to predict a continuous behavioral\nvariable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Author**: `Dhaif BEKHA <dhaif@dhaifbekha.com>`_\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve the example dataset\n----------------------------\n\nIn this example, we will work directly on a pre-computed dictionary,\nthat contain two set of connectivity matrices, from two different groups.\nThe first group, called *controls* is a set of connectivity matrices from healthy\nseven years old children, and the second group called *patients*, is a set of\nconnectivity matrices from seven years old children who have suffered a stroke.\nYou can download the dictionary use in this example\n`here <https://www.dropbox.com/s/kwdrx4liauo10kr/raw_subjects_connectivity_matrices.pkl?dl=1>`_.\nIn this example we will try to predict a continuous variable from the connectivity matrices. Therefore, you\ncan also download a\n`table <https://www.dropbox.com/scl/fi/w5mxeel9ihmlksxfz88or/regression_data.xlsx?dl=1&rlkey=3srxro9jm8k0e2asbwfetxnjl>`_\n, containing one behavioral variable for all subject in the patients group.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Module import\n-------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nfrom pathlib import Path\nimport os\nfrom conpagnon.utils.folders_and_files_management import load_object\nfrom conpagnon.machine_learning.CPM_method import predictors_selection_correlation, \\\n    compute_summary_subjects_summary_values, fit_model_on_training_set, predict_behavior\nfrom conpagnon.plotting.display import plot_matrix\nimport numpy as np\nfrom nilearn.connectome import sym_matrix_to_vec, vec_to_sym_matrix\nimport time\nfrom joblib import delayed, Parallel\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load data, and set Path\n-----------------------\n\nFor this section of the tutorial, we will simply need a set\nof connectivity matrices, and a continuous behavioral score.\nTraditionally a score is simply a measure of an individual performance\nfor a particular cognitive task. In our case,\nfor this simple example, this score\nwill be interpreted as the mean performance\nfor a battery of sub-test regarding the language function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fetch the path of the home directory\nhome_directory = str(Path.home())\n\n# Load the dictionary containing the connectivity matrices\nsubjects_connectivity_matrices = load_object(\n    full_path_to_object=os.path.join(home_directory, 'raw_subjects_connectivity_matrices.pkl'))\n\n# Load the data table\ndata_path = os.path.join(home_directory, 'regression_data.xlsx')\ndata_table = pd.read_excel(data_path)\n\n# Print the data table\nprint(data_table.to_markdown())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Connectome Predictive Modelling: the algorithm\n----------------------------------------------\n\nConnectome Predictive Modelling (**CPM**), is fairly new\nsimple algorithm for the prediction of behavioral scores\ndeveloped by *Shen et al* and explain in\ndetailed in their `paper <https://www.nature.com/articles/nprot.2016.178>`_.\nIn this section, we will detailed the main steps of this algorithm\nbefore diving into the Python implementation that you'll find in ConPagnon.\nCPM, is a data driven method with the aim of building\npredictive models for the brain-behavior relationship using\nthe well known method of cross-validation.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. important::\n  We detailed the main steps of the CPM algorithm, but\n  in practice we build a function which wrap all\n  the necessary step, including the cross validation.\n  Indeed, all the steps we will see below are wrapped\n  in a loop, the **cross validation loop**, in which\n  we repeat all the steps on the **training set**. The\n  cross validation method for CPM is **Leave-One-out**,\n  meaning that, at each iteration, a subject is taking\n  away from the dataset, and the rest of it, is the\n  training set. For simplicity, we will detailed the steps\n  of the CPM method, for one iteration only, i.e, one\n  split of the dataset, until the step 4, in which\n  we will finally run the entire prediction process.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 1: Features selections\n~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTraditionally, functional connectivity are high\ndimensional matrices, and the number of connectivity\ncoefficient (**features**, in the machine learning field),\nare often far more superior than the number of subjects in your\nstudy. That ratio, affect in a very negative way the performance\nof machine learning predictive models. This is often called the\n**cursed of dimensionality**. One very popular way to reduce this\neffect and increase the accuracy of prediction, is to carefully\n**select features** before feeding them to a model. In the CPM algorithm,\nthe very first step is a features selection step. There is various\nway to pre-select the features, but the most simple is to compute\nthe linear **correlation between the functional connectivity and\nthe behavioral variable**.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's compute the correlation between the language performance\n# and functional connectivity for the correlation metric.\n\n# Fetch the subjects list from the data table\ndata_table = data_table.set_index('subjects')\nsubjects_list = list(data_table.index)\n\n# Stack the connectivity matrices, following\n# the subjects_list\npatients_correlation_matrices = np.array([subjects_connectivity_matrices['patients'][s]['correlation']\n                                          for s in subjects_list])\nvectorized_correlation_matrices = sym_matrix_to_vec(symmetric=patients_correlation_matrices,\n                                                    discard_diagonal=True)\nprint('We have {} observations (i.e, number of subjects), '\n      'and {} features (i.e connectivity coefficients).'.format(vectorized_correlation_matrices.shape[0],\n                                                                vectorized_correlation_matrices.shape[1]))\n\n# Split the dataset into training set and test test\n# using the leave one out cross-validation scheme:\n# training set, test set for the connectivity matrices:\ntraining_correlation_matrices = vectorized_correlation_matrices[:-1]\ntest_correlation_matrix = vectorized_correlation_matrices[-1:]\n\n# training set, test for the language performance:\n# We put all the language scores in a (n_subjects, 1) vector\n# for convenience, because the function that we will call\n# for computing the correlation only accept that shape.\nlanguage_performance = np.zeros((len(subjects_list), 1))\nlanguage_performance[:, 0] = np.array(data_table['language_performance'])\n\ntraining_language_scores = language_performance[:-1]\ntest_language_score = language_performance[-1:]\n\nprint('We will train the CPM algorithm on {} subjects and test the CPM model on {} subject'.format(\n    training_correlation_matrices.shape[0], test_correlation_matrix.shape[0]\n))\n\n# Finally, we compute the correlation between the\n# language performance and the functional connectivity\n\n# Correlation between the language performance and connectivity\n# coefficients on the training set.\nr_matrix, p_matrix = predictors_selection_correlation(\n    training_connectivity_matrices=training_correlation_matrices,\n    training_set_behavioral_scores=training_language_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the correlation is simply a vector of\ncorrelation values, and we also compute the corresponding\np-values for each connectivity coefficients. Finally, we\nwant to select the edges in our connectivity matrices with\na p-value below a certain threshold, usually, 0.05, or 0.01.\nThis final step is wrapped in a function in the next section.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. important::\n  The correlation is not the only way of selecting\n  features. You may want to select features by also\n  adding **confounding variables**, and in that case\n  the *partial correlation* is more appropriate. Or\n  you have multiple variables, with a simple **linear model**\n  as a pre-selection step. Please, see the doctring of the\n  :py:func:`conpagnon.machine_learning.CPM_method.predictor_selection_pcorrelation` and\n  :py:func:`conpagnon.machine_learning.CPM_method.predictors_selection_linear_model` functions.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The selection step done, we can now move to the second step which is the **features\nsummarization**.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 2: Features summarization\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nIn this step, we will call the function that select the edges with\na p-value below a user defined threshold, and we will condense the\nsurviving edges in two values, for each subject, called **summary values**.\nIndeed, when the correlation is computed, some edges are naturally **positively**\ncorrelated with the behavioral score, and some edges are **negatively** correlated\nwith the behavioral score. The idea here, is to compute the linear **sum** for each\nsubject for the positively correlated edges in one hand, and the negatively correlated\nedges in the other hand. Let's called those quantities ${ \\sum_{+}^{}}{}$ and\n${ \\sum_{-}^{}}{}$. Now, a subject can be describe with only quantities:\n${{ \\sum_{+}^{}}{}, { \\sum_{-}^{}}{}, languageScore}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Compute the summary values, after selecting\n# the surviving edges at a threshold of 0.05.\nnegative_edges_mask, positive_edges_mask, negative_edges_summary_values, \\\n           positive_edges_summary_values = compute_summary_subjects_summary_values(\n            training_connectivity_matrices=training_correlation_matrices,\n            significance_selection_threshold=0.05,\n            R_mat=r_matrix,\n            P_mat=p_matrix\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The above function compute non only the summary values, but also\n  two binary mask, one for the positively correlated edges, one for\n  the negatively correlated edges, storing the selected edges before\n  the computation of those summary values. It will be useful for\n  plotting purposes, to know which edges was selected !</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 3: Build the linear model\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThe third step in the CPM protocols, is to train\na linear model on the training set, with the summary\nvalues computed above as the new features. Note that,\nany additional variable can be added here, if you find\nit relevant. The linear model can simply be written like\nthis, for the sum of selected positively correlated\nedges:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{align}Behavior = \\beta_0 + \\beta_1*{ \\sum_{+}^{}}{} + \\mu_+\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and for the for the sum of selected negatively correlated\nedges:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{align}Behavior = \\beta_0 + \\beta_2*{ \\sum_{-}^{}}{} + \\mu_-\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The drastic reduction in the features, from ``2556`` connectivity coefficient to only\n2 features (the summary values, computed as the sum of the previously selected connectivity\ncoefficient) allow us to manipulate a very **simple** and **classic linear model**. As awe said\nthe cross validation method is Leave-One-Out, so as we have 25 subjects, we have 25 iterations\nof the CPM method. For this example, we only detailed **one iteration**, so in the code below,\nthere is one and only call of the fitting of the linear model on the training set, follow\nby the testing on the leftout subject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fit the a linear model for the positively correlated edges with the behavior,\n# and the negatively correlated edges with the behavior.\npositive_edge_model_fit, negative_edge_model_fit = fit_model_on_training_set(\n    negative_edges_summary_values=negative_edges_summary_values,\n    positive_edges_summary_values=positive_edges_summary_values,\n    training_set_behavioral_score=training_language_scores,\n    add_predictive_variables=None\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``positive_edge_model_fit``, ``negative_edge_model_fit``\n  are two ``statsmodels`` objects, one for the positive\n  summary values, and one for the negative summary values.\n  Those objects, contain the :py:func:`predict` method for\n  evaluating the model for a new score.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We can test those linear models on the leftout\n# subject. The first step is to compute the summary\n# values for the leftout subject:\n\n# Compute summary statistic for the left out subject\ntest_subject_positive_edges_summary_value = np.sum(np.multiply(test_correlation_matrix,\n                                                               positive_edges_mask))\ntest_subject_negative_edges_summary_value = np.sum(np.multiply(test_correlation_matrix,\n                                                               negative_edges_mask))\n\ntest_subject_variable_positive_edges = np.c_[np.ones(1), test_subject_positive_edges_summary_value]\ntest_subject_variable_negative_edges = np.c_[np.ones(1), test_subject_negative_edges_summary_value]\n\n# Test the linear model for the\n# positive edges summary values, and\n# negative one for the leftout subject\n# Fit the model of on the left out subject\nbehavior_prediction_negative_edges = \\\n    negative_edge_model_fit.predict(test_subject_variable_positive_edges)\n\nbehavior_prediction_positive_edges = \\\n    positive_edge_model_fit.predict(test_subject_variable_negative_edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We predict the language performance for the leftout subject,\nbased on the model we build on the training set. We predict\nhis score with the positive and negative summary values:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('The true language performance of the leftout subject {} is {}, \\n'\n      'and the predicted language performance with the positive summary value is {}, \\n'\n      'and with the negative summary value is {}'.format(subjects_list[-1:][0],\n                                                         test_language_score[0][0],\n                                                         behavior_prediction_positive_edges[0],\n                                                         behavior_prediction_negative_edges[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 4: Repeat and prediction evaluation\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nAs we said before, the CPM method build a linear\nmodel on a training set and test it on a test set,\nwhich is reduce here to one sample because of the\ncross validation, Leave-One-Out. We detailed above\none iteration only, and you need to repeat the entire\nprocess for the other 24 subjects. Let's call the\n**the true scores** of language performance ${y_{true}}$,\nand ${y_{pred+}}$ the **predicted** language score from the\n**positive summary values** ${ \\sum_{+}^{}}{}$, and ${y_{pred-}}$\nthe **predicted** language score from the\n**negative summary values** ${ \\sum_{-}^{}}{}$. One of the\nsimplest way of evaluating the accuracy of the CPM method, is\ncompute **the linear correlation** between the true scores\nand predicted scores:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{align}R_{pred+} = corr({y_{true}}, {y_{pred+}})\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And naturally,\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{align}R_{pred-} = corr({y_{true}}, {y_{pred-}})\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can consider those correlation coefficient as your **statistic**. The next\nand final step, is to asses the prediction significance, affecting a p-value to\neach of those correlation coefficient between predicted adn true values. In the call\nbelow, we call the function :py:func:`conpagnon.machine_learning.CPM_method.predict_behavior`.\nThis function run the **entire** prediction process and compute ${R_{pred+}}$, and\n${R_{pred-}}$. e choose a more selective significance threshold for\nthe selection feature step 0.01.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Predict the language performance, with\n# a leave-one-out cross validation:\nr_pred_positive, r_pred_negative, selected_positive_features, \\\n    selected_negative_features = predict_behavior(\n        vectorized_connectivity_matrices=vectorized_correlation_matrices,\n        behavioral_scores=np.squeeze(language_performance),\n        selection_predictor_method='correlation',\n        significance_selection_threshold=0.01,\n        confounding_variables_matrix=None,\n        add_predictive_variables=None,\n        verbose=1)\n\nprint('Correlation between predicted and true scores for the positive model: {}'.format(r_pred_positive))\n\nprint('Correlation between predicted and true scores for the negative model: {}'.format(r_pred_negative))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step 5: Assessment of prediction significance\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nWe will use **permutation testing** to generate a empirical\nnull distribution of ${R_{pred+}}$, and ${R_{pred-}}$\ncoefficient, measuring the prediction accuracy of the CPM method.\nSpecifically, permutation is done by preserving the structure\nof the connectivity matrices but randomly reassigning behavioral scores.\nAfter the true value of ${R_{pred+}}$, and ${R_{pred-}}$ are\ncalculated, we can **randomly** assign language performance to different\nsubjects, breaking the true relationship between the functional connectivity\nand the language performance. Then, with the shuffled language performance\nscores we call the ``predict_behavior()`` function again, computing new\nvalues of the correlation between the predicted scores and the true scores.\nWe repeat this process for a good number of times, like 10,000 to have\npretty good estimation of the null distribution of of ${R_{pred+}}$,\nand ${R_{pred-}}$. Finally, for each of those coefficient we can\nestimate the **p-value**, by computing the number of times that the sampled\npermutation are greater of equal to the true prediction, and divided it by\nthe number of permutations:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\begin{align}P_{pred+} = (length: R_{permuted} > R_{pred+}) / (N + 1)\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Where $N$ is the total number of permutations.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the example below, we will assess the significance of\nthe previously computed ${R_{pred+}}$,\nand ${R_{pred-}}$ with 1000 permutations for the sake\nof computation time, but in general, at least 10,000 permutations\nis recommended.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Number of permutations\nn_permutations = 1000\n\n# Build a n_permutations time\n# shuffled language performance array,\n# for increase the performance\nbehavioral_scores_permutation_matrix = np.squeeze(np.array([np.random.permutation(language_performance)\n                                                            for n in range(n_permutations)]))\n# Predict the behavior, with\n# a reassigned language performance\n# at each permutation iteration\ntic_ = time.time()\nresults_perm = Parallel(n_jobs=6, verbose=1, backend=\"multiprocessing\")(delayed(predict_behavior)(\n    vectorized_connectivity_matrices=vectorized_correlation_matrices,\n    behavioral_scores=behavioral_scores_permutation_matrix[n_perm, ...],\n    selection_predictor_method='correlation',\n    significance_selection_threshold=0.01,\n    confounding_variables_matrix=None,\n    add_predictive_variables=None,\n    verbose=0) for n_perm in range(n_permutations))\ntac_ = time.time()\nT_ = tac_ - tic_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip::\n   We use the **joblib** library to distribute\n   the computation among multiple core. The output\n   is a list, with two elements: the null distribution\n   for ${R_{pred+}}$, and the null distribution\n   for ${R_{pred-}}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "null_distribution = np.array([[results_perm[i][0], results_perm[i][1]] for i in range(n_permutations)])\n\n# Compute p-value for the positive and\n# negative distribution\npositive_null_distribution = sorted(null_distribution[:, 0])\nnegative_null_distribution = sorted(null_distribution[:, 1])\n\np_positive = (len(np.where(positive_null_distribution > r_pred_positive)[0]) / (n_permutations + 1))\np_negative = (len(np.where(negative_null_distribution > r_pred_negative)[0]) / (n_permutations + 1))\n\nprint('Positive model p-value: {}'.format(p_positive))\nprint('Negative model p-value: {}'.format(p_negative))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize null distribution, and selected features\n--------------------------------------------------\n\nThe previously computed p-value show a value superior\nthan the classical Type-I error rate, for example 0.05,\nand hence cannot be considered as statically significant.\nWe can always visualize the null distribution of both\n${R_{pred+}}$, and ${R_{pred6}}$, and\nhow far away we got from the 95% percentile of the\ndistributions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot the null distribution of the\n# predicted correlation for the positive\n# summary values model\nplt.figure()\nplt.hist(positive_null_distribution, 'auto', histtype='bar', normed=True, alpha=0.5,\n         edgecolor='black')\nplt.title('Null distribution of predicted correlation for positive features model\u00a0\\n'\n          'R_pos = {}, p_pos = {}'.format(r_pred_positive, p_positive))\nR_positive_thresh = np.percentile(positive_null_distribution, q=95)\nplt.axvline(x=r_pred_positive, color='red')\nplt.axvline(x=R_positive_thresh, color='black')\nplt.legend(['True predicted correlation', '95% threshold correlation'])\nplt.tight_layout()\nplt.show()\n\n# Plot the null distribution of the\n# predicted correlation for the negative\n# summary values model\nplt.figure()\nplt.hist(negative_null_distribution, 'auto', histtype='bar', normed=True, alpha=0.5,\n         edgecolor='black')\nplt.title('Null distribution of predicted correlation for negative features model \\n'\n          'R_neg = {}, p_neg = {}'.format(r_pred_negative, p_negative))\nR_negative_thresh = np.percentile(negative_null_distribution, q=95)\nplt.axvline(x=r_pred_negative, color='blue')\nplt.axvline(x=R_negative_thresh, color='black')\nplt.legend(['True predicted correlation', '95% threshold correlation'])\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. danger::\n  Remember that 1000 permutations is\n  **not** enough to estimate the\n  null distribution !\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally you can retrieve easily the index of the selected\nregions that goes into the computation of the summary\nvalues, with the variables ``selected_positive_features``,\nand ``selected_negative_features``. Those variable store\nthe selected features **for each iteration**. Because of the\nnature of the cross-validation, the set of feature can differ\nfrom one iteration to another in the cross-validation loop.\nThe conservative way of dealing with this, is to compute\n**the intersection** between the selected features array.\nAfter that, we can reconstruct the selected features vector\ninto a connectivity matrices structure for plotting it. For\nexample, for the **positive summary value** model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We re-build the array of selected features\n# for both the positive model\npositive_features_arrays = vec_to_sym_matrix(np.array(selected_positive_features),\n                                             diagonal=np.zeros((vectorized_correlation_matrices.shape[0],\n                                                                72)))\n\n# Find intersection node by summing all edges across subjects\npositive_sum_mask = positive_features_arrays.sum(axis=0)\npositive_sum_mask[positive_sum_mask != vectorized_correlation_matrices.shape[0]] = 0\n\n# Finally plot the selected features matrices\nplot_matrix(matrix=positive_sum_mask,\n            mpart='lower',\n            colormap='Reds',\n            linecolor='black',\n            title='Common edges with positive correlation with behavior')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}